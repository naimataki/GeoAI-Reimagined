{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a003b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "custom_imports = dict(imports=[\"geospatial_fm\"])\n",
    "\n",
    "# base options\n",
    "dist_params = dict(backend=\"nccl\")\n",
    "log_level = \"INFO\"\n",
    "load_from = None\n",
    "resume_from = None\n",
    "cudnn_benchmark = True\n",
    "\n",
    "# Define a custom dataset for similarity learning (provide paths to pairs of similar )\n",
    "dataset_type = \"SiameseGeospatialDataset\"\n",
    "samples_per_gpu = 2\n",
    "# TO BE DEFINED BY USER: data directory\n",
    "data_root = \"C:/Users/safae/Downloads/NASAdata/NASAdata\"\n",
    "num_workers = 2\n",
    "bands = [0, 1, 2, 3, 4, 5]\n",
    "tile_size = 224\n",
    "orig_nsize = 512\n",
    "crop_size = (tile_size, tile_size)\n",
    "img_suffix = \"_merged.tif\"\n",
    "seg_map_suffix = \".mask.tif\"\n",
    "ignore_index = -1\n",
    "image_nodata = -9999\n",
    "image_nodata_replace = 0\n",
    "image_to_float32 = True\n",
    "CLASSES = (\"similar\", \"dissimilar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad698ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16\n",
    "embed_dim = 768\n",
    "num_frames = 2\n",
    "num_heads = 8\n",
    "tubelet_size = 1\n",
    "max_epochs = 80\n",
    "eval_epoch_interval = 5\n",
    "\n",
    "loss_weights_multi = [\n",
    "    0.386375, 0.661126, 0.548184, 0.640482, 0.876862, 0.925186, 3.249462,\n",
    "    1.542289, 2.175141, 2.272419, 3.062762, 3.626097, 1.198702\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecde83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = [\n",
    "    dict(\n",
    "        type=\"LoadGeospatialImageFromFile\",\n",
    "        to_float32=image_to_float32,\n",
    "        channels_last=True\n",
    "    ),\n",
    "    dict(type=\"LoadGeospatialAnnotations\", reduce_zero_label=False),\n",
    "    dict(type=\"BandsExtract\", bands=bands),\n",
    "    dict(type=\"RandomFlip\", prob=0.5),\n",
    "    dict(type=\"ToTensor\", keys=[\"img\", \"gt_semantic_seg\"]),\n",
    "    # to channels first\n",
    "    dict(type=\"TorchPermute\", keys=[\"img\"], order=(2, 0, 1)),\n",
    "    dict(type=\"TorchRandomCrop\", crop_size=(tile_size, tile_size)),\n",
    "    dict(\n",
    "        type=\"Reshape\",\n",
    "        keys=[\"img\"],\n",
    "        new_shape=(\n",
    "            len(bands),\n",
    "            num_frames,\n",
    "            tile_size,\n",
    "            tile_size\n",
    "        )\n",
    "    ),\n",
    "    dict(\n",
    "        type=\"Reshape\",\n",
    "        keys=[\"gt_semantic_seg\"],\n",
    "        new_shape=(1, tile_size, tile_size)\n",
    "    ),\n",
    "    dict(\n",
    "        type=\"CastTensor\",\n",
    "        keys=[\"gt_semantic_seg\"],\n",
    "        new_type=\"torch.LongTensor\"\n",
    "    ),\n",
    "    dict(type=\"Collect\", keys=[\"img\", \"gt_semantic_seg\"])\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(\n",
    "        type=\"LoadGeospatialImageFromFile\",\n",
    "        to_float32=image_to_float32,\n",
    "        channels_last=True\n",
    "    ),\n",
    "    dict(type=\"BandsExtract\", bands=bands),\n",
    "    dict(type=\"ToTensor\", keys=[\"img\"]),\n",
    "    # to channels first\n",
    "    dict(type=\"TorchPermute\", keys=[\"img\"], order=(2, 0, 1)),\n",
    "    dict(\n",
    "        type=\"Reshape\",\n",
    "        keys=[\"img\"],\n",
    "        new_shape=(len(bands), num_frames, -1, -1),\n",
    "        look_up=dict({\n",
    "            \"2\": 1,\n",
    "            \"3\": 2\n",
    "        })),\n",
    "    dict(type=\"CastTensor\", keys=[\"img\"], new_type=\"torch.FloatTensor\"),\n",
    "    dict(\n",
    "        type=\"CollectTestList\",\n",
    "        keys=[\"img\"],\n",
    "        meta_keys=[\n",
    "            \"img_info\",\n",
    "            \"seg_fields\",\n",
    "            \"img_prefix\",\n",
    "            \"seg_prefix\",\n",
    "            \"filename\",\n",
    "            \"ori_filename\",\n",
    "            \"img\",\n",
    "            \"img_shape\",\n",
    "            \"ori_shape\",\n",
    "            \"pad_shape\",\n",
    "            \"scale_factor\",\n",
    "        ]\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89523b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(\n",
    "    samples_per_gpu=samples_per_gpu,\n",
    "    workers_per_gpu=num_workers,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        similar_pairs_file=\"C:/Users/safae/Downloadssimilarimages\",\n",
    "        img_suffix=img_suffix,\n",
    "        pipeline=train_pipeline,\n",
    "    ),\n",
    "    # Validation and test datasets can also be provided with similar/dissimilar pairs\n",
    "    # ...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68195119",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = dict(\n",
    "    train='C:\\Users\\safae\\Downloads\\TrainData',\n",
    "    val= 'C:/Users/safae/Downloads/ValData',\n",
    "    test=  'C:\\Users\\safae\\Downloads\\ValData'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e4df92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'ContrastiveLoss', 'margin': 0.5, 'pos_weight': 1.0, 'neg_weight': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Define a custom loss function for similarity learning\n",
    "loss_func = dict(\n",
    "    type=\"ContrastiveLoss\",  # You can use ContrastiveLoss or TripletLoss\n",
    "    margin=0.5,  # Margin parameter for contrastive loss\n",
    "    pos_weight=1.0,  # Weight for the positive pairs loss\n",
    "    neg_weight=1.0,  # Weight for the negative pairs loss\n",
    ")\n",
    "print(loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68f8576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = dict(type=\"Adam\", lr=1.3e-05, betas=(0.9, 0.999))\n",
    "optimizer_config = dict(grad_clip=None)\n",
    "lr_config = dict(\n",
    "    policy=\"poly\",\n",
    "    warmup=\"linear\",\n",
    "    warmup_iters=1500,\n",
    "    warmup_ratio=1e-06,\n",
    "    power=1.0,\n",
    "    min_lr=0.0,\n",
    "    by_epoch=False\n",
    ")\n",
    "log_config = dict(\n",
    "    interval=20,\n",
    "    hooks=[\n",
    "        dict(type=\"TextLoggerHook\", by_epoch=False),\n",
    "        dict(type=\"TensorboardLoggerHook\", by_epoch=False)\n",
    "    ]\n",
    ")\n",
    "checkpoint_config = dict(\n",
    "    by_epoch=True,\n",
    "    interval=10,\n",
    ")\n",
    "evaluation = dict(\n",
    "    metric=\"mIoU\",\n",
    "    pre_eval=True,\n",
    "    save_best=\"mIoU\",\n",
    "    by_epoch=False\n",
    ")\n",
    "\n",
    "loss_func = dict(\n",
    "    type=\"DiceLoss\",\n",
    "    use_sigmoid=False,\n",
    "    loss_weight=1,\n",
    "    ignore_index=-1\n",
    ")\n",
    "\n",
    "workflow = [(\"train\", 1)]\n",
    "norm_cfg = dict(type=\"BN\", requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50067ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dict(\n",
    "    type=\"TemporalEncoderDecoder\",\n",
    "    frozen_backbone=False,\n",
    "    backbone=dict(\n",
    "        type=\"TemporalViTEncoder\",\n",
    "        patch_size=patch_size,\n",
    "        num_frames=num_frames,\n",
    "        tubelet_size=tubelet_size,\n",
    "        in_chans=len(bands),\n",
    "        embed_dim=embed_dim,\n",
    "        depth=12,\n",
    "        num_heads=num_heads,\n",
    "        mlp_ratio=4.0,\n",
    "        norm_pix_loss=False\n",
    "    ),\n",
    "    neck=dict(\n",
    "        type=\"ConvTransformerTokensToEmbeddingNeck\",\n",
    "        embed_dim=embed_dim*num_frames,\n",
    "        output_embed_dim=output_embed_dim,\n",
    "        drop_cls_token=True,\n",
    "        Hp=14,\n",
    "        Wp=14\n",
    "    ),\n",
    "    decode_head=dict(\n",
    "        num_classes=len(CLASSES),\n",
    "        in_channels=output_embed_dim,\n",
    "        type=\"FCNHead\",\n",
    "        in_index=-1,\n",
    "        channels=256,\n",
    "        num_convs=1,\n",
    "        concat_input=False,\n",
    "        dropout_ratio=0.1,\n",
    "        norm_cfg=dict(type=\"BN\", requires_grad=True),\n",
    "        align_corners=False,\n",
    "        loss_decode=loss_func\n",
    "    ),\n",
    "    auxiliary_head=dict(\n",
    "        num_classes=len(CLASSES),\n",
    "        in_channels=output_embed_dim,\n",
    "        type=\"FCNHead\",\n",
    "        in_index=-1,\n",
    "        channels=256,\n",
    "        num_convs=2,\n",
    "        concat_input=False,\n",
    "        dropout_ratio=0.1,\n",
    "        norm_cfg=dict(type=\"BN\", requires_grad=True),\n",
    "        align_corners=False,\n",
    "        loss_decode=loss_func\n",
    "    ),\n",
    "    train_cfg=dict(),\n",
    "    test_cfg=dict(\n",
    "        mode=\"slide\",\n",
    "        stride=(int(tile_size / 2), int(tile_size / 2)),\n",
    "        crop_size=(tile_size, tile_size),\n",
    "    ),\n",
    ")\n",
    "gpu_ids = range(0, 1)\n",
    "auto_resume = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f379d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
